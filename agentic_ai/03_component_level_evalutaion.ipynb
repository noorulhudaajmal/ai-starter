{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22711013",
   "metadata": {},
   "source": [
    "# Adding a component-level eval to the research workflow\n",
    "\n",
    "\n",
    "We will design a **component-level evaluation** to check the quality of sources returned by the research step.  \n",
    "\n",
    "The evaluation will compare the URLs retrieved by the agent against a **predefined list of preferred domains** (e.g., `arxiv.org`, `nature.com`, `nasa.gov`).  \n",
    "\n",
    "This allows you to quantify whether the system is pulling information from trustworthy sources, using an **objective, per-example ground truth evaluation**.\n",
    "\n",
    "\n",
    "###  overview\n",
    "\n",
    "The idea is to verify whether the web search tool is returning sources from preferred domains, and to quantify the ratio of preferred vs. total results. This evaluation will be implemented as a single function that performs an **objective, per-example check**. It will:\n",
    "\n",
    "* Parse the Tavily output (web search tool).  \n",
    "* Identify which URLs belong to the list of **preferred domains**.  \n",
    "* Compute the ratio of preferred vs. total retrieved sources.  \n",
    "* Return both a boolean flag (**PASS/FAIL**) and a Markdown-formatted summary that can be embedded directly into reports.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9723175",
   "metadata": {
    "deletable": false,
    "editable": false,
    "height": 302
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Imports\n",
    "# =========================\n",
    "\n",
    "# --- Standard library \n",
    "from datetime import datetime\n",
    "import json\n",
    "import re\n",
    "\n",
    "# --- Third-party ---\n",
    "from aisuite import Client\n",
    "\n",
    "# --- Local / project ---\n",
    "import research_tools\n",
    "import utils\n",
    "\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47e7c90a",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a511b2",
   "metadata": {},
   "source": [
    "## Defining Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2923304b",
   "metadata": {
    "height": 183
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from tavily import TavilyClient\n",
    "import wikipedia\n",
    "\n",
    "# Init env\n",
    "load_dotenv()  # load variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0970935",
   "metadata": {
    "height": 1237
   },
   "outputs": [],
   "source": [
    "# Set user-agent for requests to arXiv\n",
    "session = requests.Session()\n",
    "session.headers.update({\n",
    "    \"User-Agent\": \"LF-ADP-Agent/1.0 (mailto:your.email@example.com)\"\n",
    "})\n",
    "\n",
    "def arxiv_search_tool(query: str, max_results: int = 5) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Searches arXiv for research papers matching the given query.\n",
    "    \"\"\"\n",
    "    url = f\"https://export.arxiv.org/api/query?search_query=all:{query}&start=0&max_results={max_results}\"\n",
    "\n",
    "    try:\n",
    "        response = session.get(url, timeout=60)\n",
    "        response.raise_for_status()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return [{\"error\": str(e)}]\n",
    "\n",
    "    try:\n",
    "        root = ET.fromstring(response.content)\n",
    "        ns = {'atom': 'http://www.w3.org/2005/Atom'}\n",
    "\n",
    "        results = []\n",
    "        for entry in root.findall('atom:entry', ns):\n",
    "            title = entry.find('atom:title', ns).text.strip()\n",
    "            authors = [author.find('atom:name', ns).text for author in entry.findall('atom:author', ns)]\n",
    "            published = entry.find('atom:published', ns).text[:10]\n",
    "            url_abstract = entry.find('atom:id', ns).text\n",
    "            summary = entry.find('atom:summary', ns).text.strip()\n",
    "\n",
    "            link_pdf = None\n",
    "            for link in entry.findall('atom:link', ns):\n",
    "                if link.attrib.get('title') == 'pdf':\n",
    "                    link_pdf = link.attrib.get('href')\n",
    "                    break\n",
    "\n",
    "            results.append({\n",
    "                \"title\": title,\n",
    "                \"authors\": authors,\n",
    "                \"published\": published,\n",
    "                \"url\": url_abstract,\n",
    "                \"summary\": summary,\n",
    "                \"link_pdf\": link_pdf\n",
    "            })\n",
    "\n",
    "        return results\n",
    "    except Exception as e:\n",
    "        return [{\"error\": f\"Parsing failed: {str(e)}\"}]\n",
    "\n",
    "\n",
    "arxiv_tool_def = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"arxiv_search_tool\",\n",
    "        \"description\": \"Searches for research papers on arXiv by query string.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Search keywords for research papers.\"\n",
    "                },\n",
    "                \"max_results\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"Maximum number of results to return.\",\n",
    "                    \"default\": 5\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6173241",
   "metadata": {
    "height": 1339
   },
   "outputs": [],
   "source": [
    "def tavily_search_tool(query: str, max_results: int = 5, include_images: bool = False) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Perform a search using the Tavily API.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query.\n",
    "        max_results (int): Number of results to return (default 5).\n",
    "        include_images (bool): Whether to include image results.\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: A list of dictionaries with keys like 'title', 'content', and 'url'.\n",
    "    \"\"\"\n",
    "    params = {}\n",
    "    api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise ValueError(\"TAVILY_API_KEY not found in environment variables.\")\n",
    "    params['api_key'] = api_key\n",
    "\n",
    "    #client = TavilyClient(api_key)\n",
    "\n",
    "    api_base_url = os.getenv(\"DLAI_TAVILY_BASE_URL\")\n",
    "    if api_base_url:\n",
    "        params['api_base_url'] = api_base_url\n",
    "\n",
    "    client = TavilyClient(api_key=api_key, base_url=api_base_url)\n",
    "\n",
    "    try:\n",
    "        response = client.search(\n",
    "            query=query,\n",
    "            max_results=max_results,\n",
    "            include_images=include_images\n",
    "        )\n",
    "\n",
    "        results = []\n",
    "        for r in response.get(\"results\", []):\n",
    "            results.append({\n",
    "                \"title\": r.get(\"title\", \"\"),\n",
    "                \"content\": r.get(\"content\", \"\"),\n",
    "                \"url\": r.get(\"url\", \"\")\n",
    "            })\n",
    "\n",
    "        if include_images:\n",
    "            for img_url in response.get(\"images\", []):\n",
    "                results.append({\"image_url\": img_url})\n",
    "\n",
    "        return results\n",
    "\n",
    "    except Exception as e:\n",
    "        return [{\"error\": str(e)}]  # For LLM-friendly agents\n",
    "    \n",
    "\n",
    "tavily_tool_def = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"tavily_search_tool\",\n",
    "        \"description\": \"Performs a general-purpose web search using the Tavily API.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Search keywords for retrieving information from the web.\"\n",
    "                },\n",
    "                \"max_results\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"Maximum number of results to return.\",\n",
    "                    \"default\": 5\n",
    "                },\n",
    "                \"include_images\": {\n",
    "                    \"type\": \"boolean\",\n",
    "                    \"description\": \"Whether to include image results.\",\n",
    "                    \"default\": False\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ba52502",
   "metadata": {
    "height": 829
   },
   "outputs": [],
   "source": [
    "## Wikipedia search tool\n",
    "def wikipedia_search_tool(query: str, sentences: int = 5) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Searches Wikipedia for a summary of the given query.\n",
    "\n",
    "    Args:\n",
    "        query (str): Search query for Wikipedia.\n",
    "        sentences (int): Number of sentences to include in the summary.\n",
    "\n",
    "    Returns:\n",
    "        list[dict]: A list with a single dictionary containing title, summary, and URL.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        page_title = wikipedia.search(query)[0]\n",
    "        page = wikipedia.page(page_title)\n",
    "        summary = wikipedia.summary(page_title, sentences=sentences)\n",
    "\n",
    "        return [{\n",
    "            \"title\": page.title,\n",
    "            \"summary\": summary,\n",
    "            \"url\": page.url\n",
    "        }]\n",
    "    except Exception as e:\n",
    "        return [{\"error\": str(e)}]\n",
    "\n",
    "# Tool definition\n",
    "wikipedia_tool_def = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"wikipedia_search_tool\",\n",
    "        \"description\": \"Searches for a Wikipedia article summary by query string.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"query\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Search keywords for the Wikipedia article.\"\n",
    "                },\n",
    "                \"sentences\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"Number of sentences in the summary.\",\n",
    "                    \"default\": 5\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"query\"]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72a96e3d",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "# Tool mapping\n",
    "tool_mapping = {\n",
    "    \"tavily_search_tool\": tavily_search_tool,\n",
    "    \"arxiv_search_tool\": arxiv_search_tool,\n",
    "    \"wikipedia_search_tool\": wikipedia_search_tool\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea1ac58",
   "metadata": {},
   "source": [
    "## Research Step\n",
    "\n",
    "Defining a function `find_references` for web search functionality(**gather external information** from tools such as **Arxiv**, **Tavily**, and **Wikipedia**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87d88063",
   "metadata": {
    "height": 591
   },
   "outputs": [],
   "source": [
    "def find_references(task: str, model: str = \"openai:gpt-4o\", return_messages: bool = False):\n",
    "    \"\"\"Perform a research task using external tools (arxiv, tavily, wikipedia).\"\"\"\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are a research function with access to:\n",
    "    - arxiv_tool: academic papers\n",
    "    - tavily_tool: general web search (return JSON when asked)\n",
    "    - wikipedia_tool: encyclopedic summaries\n",
    "\n",
    "    Task:\n",
    "    {task}\n",
    "\n",
    "    Today is {datetime.now().strftime('%Y-%m-%d')}.\n",
    "    \"\"\".strip()\n",
    "\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    tools = [\n",
    "        research_tools.arxiv_search_tool,\n",
    "        research_tools.tavily_search_tool,\n",
    "        research_tools.wikipedia_search_tool,\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            tools=tools,\n",
    "            tool_choice=\"auto\",\n",
    "            max_turns=5,\n",
    "        )\n",
    "        content = response.choices[0].message.content\n",
    "        return (content, messages) if return_messages else content\n",
    "    except Exception as e:\n",
    "        return f\"[Model Error: {e}]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7sbp6250z5l",
   "metadata": {
    "height": 81
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I couldn't find recent papers published around your specification, but here are two papers on recent developments in black hole science available via arXiv:\n",
      "\n",
      "1. **Title**: [Accretion onto Supermassive Black Holes in Quasars: Learning from Optical/UV Observations](http://arxiv.org/abs/astro-ph/0606678v1)  \n",
      "   **Authors**: Paola Marziani, Deborah Dultzin-Hacyan, Jack W. Sulentic  \n",
      "   **Published**: 2006-06-28  \n",
      "   **Summary**: This paper explores the complexities of accretion processes in quasars and active galactic nuclei, which are critical to understanding black hole physics and dynamics. It emphasizes the current research aimed at accurately measuring black hole mass and accretion rates using optical and UV broad emission lines. These measurements are key to understanding the evolution of quasars and related cosmological phenomena.\n",
      "   [Read PDF](https://arxiv.org/pdf/astro-ph/0606678v1) \n",
      "\n",
      "2. **Title**: [Disturbing the Black Hole](http://arxiv.org/abs/gr-qc/9805045v1)  \n",
      "   **Authors**: Jacob D. Bekenstein  \n",
      "   **Published**: 1998-05-13  \n",
      "   **Summary**: This paper provides examples supporting the idea that the horizon area of a near-equilibrium black hole is an adiabatic invariant. The study focuses on various types of black holes influenced by different perturbations and highlights the potential for black hole quantization.  \n",
      "   [Read PDF](https://arxiv.org/pdf/gr-qc/9805045v1) \n",
      "\n",
      "These papers, though not from recent years, contribute to ongoing discussions and developments in black hole science.\n"
     ]
    }
   ],
   "source": [
    "research_task = \"Find 2 recent papers about recent developments in black hole science\"\n",
    "research_result = find_references(research_task)\n",
    "\n",
    "print(research_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cd3d9e",
   "metadata": {},
   "source": [
    "## Evaluation Step\n",
    "\n",
    "Not all sources retrieved by web search are equally reliable.  \n",
    "\n",
    "- If the problem lies in web search (usually the **first step** in a graded lab workflow), rerunning the *entire* pipeline (search → draft → reflect) every time can be **expensive** and noisy.  \n",
    "- Small improvements in web search quality may be hidden by randomness introduced by later components.  \n",
    "- By evaluating the web search *alone*, you get a **clearer signal** of whether that component is improving.  \n",
    "\n",
    "Component-level evals are also efficient when multiple teams are working on different pieces of a system: each team can optimize its own component using a clear metric, without needing to run or wait for full end-to-end tests.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5f37d50",
   "metadata": {
    "height": 319
   },
   "outputs": [],
   "source": [
    "# list of preferred domains for Tavily results\n",
    "TOP_DOMAINS = {\n",
    "    # General reference / institutions / publishers\n",
    "    \"wikipedia.org\", \"nature.com\", \"science.org\", \"sciencemag.org\", \"cell.com\",\n",
    "    \"mit.edu\", \"stanford.edu\", \"harvard.edu\", \"nasa.gov\", \"noaa.gov\", \"europa.eu\",\n",
    "\n",
    "    # CS/AI venues & indexes\n",
    "    \"arxiv.org\", \"acm.org\", \"ieee.org\", \"neurips.cc\", \"icml.cc\", \"openreview.net\",\n",
    "\n",
    "    # Other reputable outlets\n",
    "    \"elifesciences.org\", \"pnas.org\", \"jmlr.org\", \"springer.com\", \"sciencedirect.com\",\n",
    "\n",
    "    # Extra domains (case-specific additions)\n",
    "    \"pbs.org\", \"nova.edu\", \"nvcc.edu\", \"cccco.edu\",\n",
    "\n",
    "    # Well known programming sites\n",
    "    \"codecademy.com\", \"datacamp.com\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "192407dc",
   "metadata": {
    "height": 914
   },
   "outputs": [],
   "source": [
    "def evaluate_tavily_results(TOP_DOMAINS, raw: str, min_ratio=0.4):\n",
    "    \"\"\"\n",
    "    Evaluate whether plain-text research results mostly come from preferred domains.\n",
    "\n",
    "    Args:\n",
    "        TOP_DOMAINS (set[str]): Set of preferred domains (e.g., 'arxiv.org', 'nature.com').\n",
    "        raw (str): Plain text or Markdown containing URLs.\n",
    "        min_ratio (float): Minimum preferred ratio required to pass (e.g., 0.4 = 40%).\n",
    "\n",
    "    Returns:\n",
    "        tuple[bool, str]: (flag, markdown_report)\n",
    "        flag -> True if PASS, False if FAIL\n",
    "        markdown_report -> Markdown-formatted summary of the evaluation\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract URLs from the text\n",
    "    url_pattern = re.compile(r'https?://[^\\s\\]\\)>\\}]+', flags=re.IGNORECASE)\n",
    "    urls = url_pattern.findall(raw)\n",
    "\n",
    "    if not urls:\n",
    "        return False, \"\"\"### Evaluation — Tavily Preferred Domains\n",
    "        No URLs detected in the provided text. \n",
    "        Please include links in your research results.\n",
    "        \"\"\"\n",
    "\n",
    "    # Count preferred vs total\n",
    "    total = len(urls)\n",
    "    preferred_count = 0\n",
    "    details = []\n",
    "\n",
    "    for url in urls:\n",
    "        domain = url.split(\"/\")[2]\n",
    "        preferred = any(td in domain for td in TOP_DOMAINS)\n",
    "        if preferred:\n",
    "            preferred_count += 1\n",
    "        details.append(f\"- {url} → {'✅ PREFERRED' if preferred else '❌ NOT PREFERRED'}\")\n",
    "\n",
    "    ratio = preferred_count / total if total > 0 else 0.0\n",
    "    flag = ratio >= min_ratio\n",
    "\n",
    "    # Markdown report\n",
    "    report = f\"\"\"\n",
    "    ### Evaluation — Tavily Preferred Domains\n",
    "    - Total results: {total}\n",
    "    - Preferred results: {preferred_count}\n",
    "    - Ratio: {ratio:.2%}\n",
    "    - Threshold: {min_ratio:.0%}\n",
    "    - Status: {\"✅ PASS\" if flag else \"❌ FAIL\"}\n",
    "\n",
    "    **Details:**\n",
    "    {chr(10).join(details)}\n",
    "    \"\"\"\n",
    "    return flag, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36a13742",
   "metadata": {
    "height": 166
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Trusted Domains: \n",
      "[\n",
      "  \"noaa.gov\",\n",
      "  \"wikipedia.org\",\n",
      "  \"codecademy.com\",\n",
      "  \"pnas.org\"\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "Research Results: \n",
      "I couldn't find recent papers published around your specification, but here are two papers on recent developments in black hole science available via arXiv:\n",
      "\n",
      "1. **Title**: [Accretion onto Supermassive Black Holes in Quasars: Learning from Optical/UV Observations](http://arxiv.org/abs/astro-ph/0606678v1)  \n",
      "   **Authors**: Paola Marziani, Deborah Dultzin-Hacyan, Jack W. Sulentic  \n",
      "   **Published**: 2006-06-28  \n",
      "   **Summary**: This paper explores the complexities of accretion processes in quasars and active galactic nuclei, which are critical to understanding black hole physics and dynamics. It emphasizes the current research aimed at accurately measuring black hole mass and accretion rates using optical and UV broad emission lines. These measurements are key to understanding the evolution of quasars and related cosmological phenomena.\n",
      "   [Read PDF](https://arxiv.org/pdf/astro-ph/0606678v1) \n",
      "\n",
      "2. **Title**: [Disturbing the Black Hole](http://arxiv.org/abs/gr-qc/9805045v1)  \n",
      "   **Authors**: Jacob D. Bekenstein  \n",
      "   **Published**: 1998-05-13  \n",
      "   **Summary**: This paper provides examples supporting the idea that the horizon area of a near-equilibrium black hole is an adiabatic invariant. The study focuses on various types of black holes influenced by different perturbations and highlights the potential for black hole quantization.  \n",
      "   [Read PDF](https://arxiv.org/pdf/gr-qc/9805045v1) \n",
      "\n",
      "These papers, though not from recent years, contribute to ongoing discussions and developments in black hole science.\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "    ### Evaluation — Tavily Preferred Domains\n",
       "    - Total results: 4\n",
       "    - Preferred results: 4\n",
       "    - Ratio: 100.00%\n",
       "    - Threshold: 40%\n",
       "    - Status: ✅ PASS\n",
       "\n",
       "    **Details:**\n",
       "    - http://arxiv.org/abs/astro-ph/0606678v1 → ✅ PREFERRED\n",
       "- https://arxiv.org/pdf/astro-ph/0606678v1 → ✅ PREFERRED\n",
       "- http://arxiv.org/abs/gr-qc/9805045v1 → ✅ PREFERRED\n",
       "- https://arxiv.org/pdf/gr-qc/9805045v1 → ✅ PREFERRED\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Summary: \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(f\"Sample Trusted Domains: \\n{json.dumps(list(TOP_DOMAINS)[:4], indent=2)}\\n{'-'*50}\\n\")\n",
    "print(f\"Research Results: \\n{research_result}\\n{'-'*50}\\n\")\n",
    "\n",
    "flag, report = evaluate_tavily_results(TOP_DOMAINS, research_result)\n",
    "print(f\"Evaluation Summary: \\n{display(Markdown(report))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a356ad37",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ceb0548",
   "metadata": {
    "height": 489
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Preferred Domains: \n",
      "[\n",
      "  \"stanford.edu\",\n",
      "  \"wikipedia.org\",\n",
      "  \"nasa.gov\",\n",
      "  \"harvard.edu\"\n",
      "]\n",
      "--------------------------------------------------\n",
      "\n",
      "Research Results: \n",
      "I couldn't find recent papers published around your specification, but here are two papers on recent developments in black hole science available via arXiv:\n",
      "\n",
      "1. **Title**: [Accretion onto Supermassive Black Holes in Quasars: Learning from Optical/UV Observations](http://arxiv.org/abs/astro-ph/0606678v1)  \n",
      "   **Authors**: Paola Marziani, Deborah Dultzin-Hacyan, Jack W. Sulentic  \n",
      "   **Published**: 2006-06-28  \n",
      "   **Summary**: This paper explores the complexities of accretion processes in quasars and active galactic nuclei, which are critical to understanding black hole physics and dynamics. It emphasizes the current research aimed at accurately measuring black hole mass and accretion rates using optical and UV broad emission lines. These measurements are key to understanding the evolution of quasars and related cosmological phenomena.\n",
      "   [Read PDF](https://arxiv.org/pdf/astro-ph/0606678v1) \n",
      "\n",
      "2. **Title**: [Disturbing the Black Hole](http://arxiv.org/abs/gr-qc/9805045v1)  \n",
      "   **Authors**: Jacob D. Bekenstein  \n",
      "   **Published**: 1998-05-13  \n",
      "   **Summary**: This paper provides examples supporting the idea that the horizon area of a near-equilibrium black hole is an adiabatic invariant. The study focuses on various types of black holes influenced by different perturbations and highlights the potential for black hole quantization.  \n",
      "   [Read PDF](https://arxiv.org/pdf/gr-qc/9805045v1) \n",
      "\n",
      "These papers, though not from recent years, contribute to ongoing discussions and developments in black hole science.\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "    ### Evaluation — Tavily Preferred Domains\n",
       "    - Total results: 7\n",
       "    - Preferred results: 7\n",
       "    - Ratio: 100.00%\n",
       "    - Threshold: 40%\n",
       "    - Status: ✅ PASS\n",
       "\n",
       "    **Details:**\n",
       "    - https://arxiv.org/abs/astro-ph/0606678v1 → ✅ PREFERRED\n",
       "- https://arxiv.org/pdf/astro-ph/0606678v1 → ✅ PREFERRED\n",
       "- http://arxiv.org/abs/gr-qc/9805045v1 → ✅ PREFERRED\n",
       "- https://arxiv.org/pdf/gr-qc/9805045v1 → ✅ PREFERRED\n",
       "- http://arxiv.org/abs/0805.3007v2 → ✅ PREFERRED\n",
       "- https://arxiv.org/pdf/0805.3007v2 → ✅ PREFERRED\n",
       "- https://en.wikipedia.org/wiki/Black_hole_information_paradox → ✅ PREFERRED\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Summary: \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "topic = \"recent developments in black hole science\" \n",
    "min_ratio = 0.4 \n",
    "run_reflection = True\n",
    "\n",
    "# Short list of preferred domains\n",
    "TOP_DOMAINS = {\n",
    "    \"wikipedia.org\", \"nature.com\", \"science.org\", \"arxiv.org\",\n",
    "    \"nasa.gov\", \"mit.edu\", \"stanford.edu\", \"harvard.edu\"\n",
    "}\n",
    "\n",
    "# Show a sample of preferred domains\n",
    "print(f\"Sample Preferred Domains: \\n{json.dumps(list(TOP_DOMAINS)[:4], indent=2)}\\n{'-'*50}\\n\")\n",
    "\n",
    "# 1) Research\n",
    "research_task = f\"Find 2–3 key papers and reliable overviews about {topic}.\"\n",
    "research_output = find_references(research_task)\n",
    "print(f\"Research Results: \\n{research_result}\\n{'-'*50}\\n\")\n",
    "\n",
    "# 2) Evaluate sources (preferred domains ratio)\n",
    "flag, eval_md = evaluate_tavily_results(TOP_DOMAINS, research_output, min_ratio=min_ratio)\n",
    "print(f\"Evaluation Summary: \\n{display(Markdown(eval_md))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3e7205",
   "metadata": {},
   "source": [
    "## Takeaways\n",
    "\n",
    "* Component-level evaluation checked whether the retrieved URLs were in a predefined list of **preferred domains**. This is an example of an **objective evaluation** with a clear **per-example ground truth**.  \n",
    "* To build an evaluation set, design ~10 prompts covering different topics (astronomy, robotics, finance, etc.) and define preferred domains for each. The percentage of retrieved sources that matched the list of preferred domains provides a useful **metric** to guide improvements, such as adjusting the prompt or tool parameters.  \n",
    "* This approach is **simpler and cheaper** than evaluating full essays with reflection and rewrites, since it only focus on the web search component.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc6bb64",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11dca272",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "grader_version": "1",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
